## Machine Learning Foundations

### When Can Machines Learn?

Lecture   |Topic   |Content   
:---|:---|:---
Week 1 |The Learning Problem|1. What is Machine Learning<br>2. Applications of Machine Learning<br>3. Components of Machine Learning<br>4. Machine Learning and Other Fields
Week 2 |Learning to Answer Yes/No|1. Perceptron Hypothesis Set<br>2. Perceptron Learning Algorithm (PLA)<br>3. Guarantee of PLA<br>4. Non-Separable Data
Week 3 |Types of Learning|1. Learning with Different Output Space<br>2. Learning with Different Data Label<br>3. Learning with Different Protocol<br>4. Learning with Different Input Space
Week 4 |Feasibility of Learning|1. Learning is Impossible?<br>2. Probability to the Rescue<br>3. Connection to Learning<br>4. Connection to Real Learning

### Why Can Machines Learn?

Lecture   |Topic   |Content   
:---|:---|:---
Week 5 |Training versus Testing|1. Recap and Preview<br>2. Effective Number of Lines<br>3. Effective Number of Hypotheses<br>4. Break Point
Week 6 |Theory of Generalization|1. Restriction of Break Point<br>2. Bounding Function: Basic Cases<br>3. Bounding Function: Inductive Cases<br>4. A Pictorial Proof
Week 7 |The VC Dimension|1. Definition of VC Dimension<br>2. VC Dimension of Perceptrons<br>3. Physical Intuition of VC Dimension<br>4. Interpreting VC Dimension
Week 8 |Noise and Error|1. Noise and Probabilistic Target<br>2. Error Measure<br>3. Algorithmic Error Measure<br>4. Weighted Classification

### How Can Machines Learn?

Lecture   |Topic   |Content   
:---|:---|:---
Week 9 |Linear Regression|1. Linear Regression Problem<br>2. Linear Regression Algorithm<br>3. Generalization Issue<br>4. Linear Regression for Binary Classification
Week 10 |Logistic Regression|1. Logistic Regression Problem<br>2. Logistic Regression Error<br>3. Gradient of Logistic Regression Error<br>4. Gradient Descent
Week 11 |Linear Models for Classification|1. Linear Models for Binary Classification<br>2. Stochastic Gradient Descent<br>3. Multiclass via Logistic Regression<br>4. Multiclass via Binary Classification
Week 12 |Nonlinear Transformation|1. Quadratic Hypotheses<br>2. Nonlinear Transform<br>3. Price of Nonlinear Transform<br>4. Structured Hypothesis Sets

### How Can Machines Learn Better?

Lecture   |Topic   |Content   
:---|:---|:---
Week 13 |Hazard of Overfitting|1. What is Overfitting?<br>2. The Role of Noise and Data Size<br>3. Deterministic Noise<br>4. Dealing with Overfitting
Week 14 |Regularization|1. Regularized Hypothesis Set<br>2. Weight Decay Regularization<br>3. Regularization and VC Theory<br>4. General Regularizers
Week 15 |Validation|1. Model Selection Problem<br>2. Validation<br>3. Leave-One-Out Cross Validation<br>4. V-Fold Cross Validation
Week 16 |Three Learning Principles|1. Occam's Razor<br>2. Sampling Bias<br>3. Data Snooping<br>4. Power of Three
